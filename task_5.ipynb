{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\dl-hw5\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import tabulate\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# pip install transformers==4.45.2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n",
      "['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('dair-ai/emotion')\n",
    "print(dataset)\n",
    "\n",
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 9433.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_data(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Токенизация всех данных\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, true_labels = eval_pred  # Переименовали переменную\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, predictions),\n",
    "        **classification_report(\n",
    "            true_labels, \n",
    "            predictions,\n",
    "            target_names=labels,  # Используем глобальный список названий\n",
    "            output_dict=True,\n",
    "            zero_division=0\n",
    "        )[\"macro avg\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 01:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 0.7932651042938232, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.7425, 'eval_precision': 0.7402512345382611, 'eval_recall': 0.5454750466210642, 'eval_f1-score': 0.5292401848522555, 'eval_support': 2000.0, 'eval_runtime': 30.2114, 'eval_samples_per_second': 66.2, 'eval_steps_per_second': 4.138}\n",
      "+-----------------------------+------------+\n",
      "| Метрика                     |   Значение |\n",
      "+=============================+============+\n",
      "| eval_loss                   |     0.7933 |\n",
      "+-----------------------------+------------+\n",
      "| eval_model_preparation_time |     0.0000 |\n",
      "+-----------------------------+------------+\n",
      "| eval_accuracy               |     0.7425 |\n",
      "+-----------------------------+------------+\n",
      "| eval_precision              |     0.7403 |\n",
      "+-----------------------------+------------+\n",
      "| eval_recall                 |     0.5455 |\n",
      "+-----------------------------+------------+\n",
      "| eval_f1-score               |     0.5292 |\n",
      "+-----------------------------+------------+\n",
      "| eval_support                |  2000.0000 |\n",
      "+-----------------------------+------------+\n",
      "| eval_runtime                |    30.2114 |\n",
      "+-----------------------------+------------+\n",
      "| eval_samples_per_second     |    66.2000 |\n",
      "+-----------------------------+------------+\n",
      "| eval_steps_per_second       |     4.1380 |\n",
      "+-----------------------------+------------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 12:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>0.602014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798500</td>\n",
       "      <td>0.795935</td>\n",
       "      <td>0.695663</td>\n",
       "      <td>0.717404</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.556300</td>\n",
       "      <td>0.401258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.863867</td>\n",
       "      <td>0.819401</td>\n",
       "      <td>0.836907</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.370869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885845</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.848792</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.298690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.886308</td>\n",
       "      <td>0.881649</td>\n",
       "      <td>0.879431</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.253372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>0.880174</td>\n",
       "      <td>0.895599</td>\n",
       "      <td>0.887184</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.242581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>0.890440</td>\n",
       "      <td>0.884771</td>\n",
       "      <td>0.885680</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.229441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923500</td>\n",
       "      <td>0.904171</td>\n",
       "      <td>0.898934</td>\n",
       "      <td>0.900193</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.210620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.893911</td>\n",
       "      <td>0.899958</td>\n",
       "      <td>0.896235</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.195859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.894704</td>\n",
       "      <td>0.911191</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.194467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.892626</td>\n",
       "      <td>0.914553</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 0.19975651800632477, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.9255, 'eval_precision': 0.8758080764820901, 'eval_recall': 0.9015332050069241, 'eval_f1-score': 0.8875884063063505, 'eval_support': 2000.0, 'eval_runtime': 22.5506, 'eval_samples_per_second': 88.689, 'eval_steps_per_second': 5.543, 'epoch': 1.0}\n",
      "+-----------------------------+------------+\n",
      "| Метрика                     |   Значение |\n",
      "+=============================+============+\n",
      "| eval_loss                   |     0.1998 |\n",
      "+-----------------------------+------------+\n",
      "| eval_model_preparation_time |     0.0000 |\n",
      "+-----------------------------+------------+\n",
      "| eval_accuracy               |     0.9255 |\n",
      "+-----------------------------+------------+\n",
      "| eval_precision              |     0.8758 |\n",
      "+-----------------------------+------------+\n",
      "| eval_recall                 |     0.9015 |\n",
      "+-----------------------------+------------+\n",
      "| eval_f1-score               |     0.8876 |\n",
      "+-----------------------------+------------+\n",
      "| eval_support                |  2000.0000 |\n",
      "+-----------------------------+------------+\n",
      "| eval_runtime                |    22.5506 |\n",
      "+-----------------------------+------------+\n",
      "| eval_samples_per_second     |    88.6890 |\n",
      "+-----------------------------+------------+\n",
      "| eval_steps_per_second       |     5.5430 |\n",
      "+-----------------------------+------------+\n",
      "| epoch                       |     1.0000 |\n",
      "+-----------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    max_steps=1000,\n",
    "    logging_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"f1-score\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    # lr_scheduler_type=\"cosine\",\n",
    "    # warmup_steps=500\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))\n",
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучается: classifier.dense.weight\n",
      "Обучается: classifier.dense.bias\n",
      "Обучается: classifier.out_proj.weight\n",
      "Обучается: classifier.out_proj.bias\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 52:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.580600</td>\n",
       "      <td>1.566283</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.130832</td>\n",
       "      <td>0.197472</td>\n",
       "      <td>0.149039</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.545700</td>\n",
       "      <td>1.558187</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.172626</td>\n",
       "      <td>0.236536</td>\n",
       "      <td>0.194022</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.516600</td>\n",
       "      <td>1.556525</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.151174</td>\n",
       "      <td>0.204422</td>\n",
       "      <td>0.150668</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.526300</td>\n",
       "      <td>1.508552</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.157347</td>\n",
       "      <td>0.245720</td>\n",
       "      <td>0.188290</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.500700</td>\n",
       "      <td>1.478144</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.159239</td>\n",
       "      <td>0.248456</td>\n",
       "      <td>0.190569</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>1.465558</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.161749</td>\n",
       "      <td>0.251250</td>\n",
       "      <td>0.192665</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.471300</td>\n",
       "      <td>1.455693</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.160201</td>\n",
       "      <td>0.253182</td>\n",
       "      <td>0.194655</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.448000</td>\n",
       "      <td>1.436043</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>0.326724</td>\n",
       "      <td>0.255758</td>\n",
       "      <td>0.198223</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.474200</td>\n",
       "      <td>1.414599</td>\n",
       "      <td>0.491000</td>\n",
       "      <td>0.217141</td>\n",
       "      <td>0.257642</td>\n",
       "      <td>0.199582</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.452200</td>\n",
       "      <td>1.413316</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>0.222652</td>\n",
       "      <td>0.262595</td>\n",
       "      <td>0.207293</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.452600</td>\n",
       "      <td>1.419103</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.274861</td>\n",
       "      <td>0.233873</td>\n",
       "      <td>0.185361</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.412900</td>\n",
       "      <td>1.408278</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165593</td>\n",
       "      <td>0.257169</td>\n",
       "      <td>0.197776</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.419200</td>\n",
       "      <td>1.384479</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.273124</td>\n",
       "      <td>0.259631</td>\n",
       "      <td>0.203474</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.433200</td>\n",
       "      <td>1.380820</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.415351</td>\n",
       "      <td>0.264972</td>\n",
       "      <td>0.206740</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.433600</td>\n",
       "      <td>1.392648</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.252252</td>\n",
       "      <td>0.260275</td>\n",
       "      <td>0.201452</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.417100</td>\n",
       "      <td>1.399185</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.408067</td>\n",
       "      <td>0.277955</td>\n",
       "      <td>0.236912</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.411900</td>\n",
       "      <td>1.362277</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.270236</td>\n",
       "      <td>0.268523</td>\n",
       "      <td>0.214850</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.421300</td>\n",
       "      <td>1.371628</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.344959</td>\n",
       "      <td>0.273220</td>\n",
       "      <td>0.223542</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.406400</td>\n",
       "      <td>1.354723</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.332456</td>\n",
       "      <td>0.269063</td>\n",
       "      <td>0.217711</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.383200</td>\n",
       "      <td>1.386985</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>0.289284</td>\n",
       "      <td>0.259849</td>\n",
       "      <td>0.204799</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.392200</td>\n",
       "      <td>1.345044</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.365087</td>\n",
       "      <td>0.269897</td>\n",
       "      <td>0.219104</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.394600</td>\n",
       "      <td>1.380483</td>\n",
       "      <td>0.494000</td>\n",
       "      <td>0.415198</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.216635</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.392000</td>\n",
       "      <td>1.364196</td>\n",
       "      <td>0.479500</td>\n",
       "      <td>0.306991</td>\n",
       "      <td>0.250948</td>\n",
       "      <td>0.201342</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.391700</td>\n",
       "      <td>1.358674</td>\n",
       "      <td>0.494500</td>\n",
       "      <td>0.366535</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.214388</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.410100</td>\n",
       "      <td>1.366363</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>0.333795</td>\n",
       "      <td>0.271194</td>\n",
       "      <td>0.227171</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.386600</td>\n",
       "      <td>1.343971</td>\n",
       "      <td>0.513500</td>\n",
       "      <td>0.407723</td>\n",
       "      <td>0.275863</td>\n",
       "      <td>0.222883</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.386500</td>\n",
       "      <td>1.335677</td>\n",
       "      <td>0.515500</td>\n",
       "      <td>0.358933</td>\n",
       "      <td>0.282095</td>\n",
       "      <td>0.236113</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.389800</td>\n",
       "      <td>1.342425</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>0.405867</td>\n",
       "      <td>0.278402</td>\n",
       "      <td>0.229267</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>1.403100</td>\n",
       "      <td>1.336592</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>0.386714</td>\n",
       "      <td>0.279442</td>\n",
       "      <td>0.234611</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.359300</td>\n",
       "      <td>1.351342</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.353711</td>\n",
       "      <td>0.269348</td>\n",
       "      <td>0.214946</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>1.391000</td>\n",
       "      <td>1.334136</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.318867</td>\n",
       "      <td>0.278147</td>\n",
       "      <td>0.233921</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>1.389400</td>\n",
       "      <td>1.332130</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.390117</td>\n",
       "      <td>0.271033</td>\n",
       "      <td>0.216022</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>1.374300</td>\n",
       "      <td>1.332340</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.334185</td>\n",
       "      <td>0.302464</td>\n",
       "      <td>0.270929</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>1.376700</td>\n",
       "      <td>1.329183</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.418584</td>\n",
       "      <td>0.272520</td>\n",
       "      <td>0.225949</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.374200</td>\n",
       "      <td>1.322735</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.332484</td>\n",
       "      <td>0.278609</td>\n",
       "      <td>0.229704</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.386400</td>\n",
       "      <td>1.331988</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.325796</td>\n",
       "      <td>0.282806</td>\n",
       "      <td>0.236974</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>1.378600</td>\n",
       "      <td>1.333059</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.369154</td>\n",
       "      <td>0.285513</td>\n",
       "      <td>0.248783</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>1.353100</td>\n",
       "      <td>1.337190</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.305281</td>\n",
       "      <td>0.277758</td>\n",
       "      <td>0.233259</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>1.384200</td>\n",
       "      <td>1.320311</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.313067</td>\n",
       "      <td>0.274840</td>\n",
       "      <td>0.225423</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.364400</td>\n",
       "      <td>1.322077</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.308644</td>\n",
       "      <td>0.285003</td>\n",
       "      <td>0.241378</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>1.374200</td>\n",
       "      <td>1.328552</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.370745</td>\n",
       "      <td>0.274045</td>\n",
       "      <td>0.220281</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.355700</td>\n",
       "      <td>1.318465</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.326646</td>\n",
       "      <td>0.281110</td>\n",
       "      <td>0.235065</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>1.363700</td>\n",
       "      <td>1.318308</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.314588</td>\n",
       "      <td>0.284557</td>\n",
       "      <td>0.245712</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>1.373400</td>\n",
       "      <td>1.319111</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>0.343934</td>\n",
       "      <td>0.275882</td>\n",
       "      <td>0.225030</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.359300</td>\n",
       "      <td>1.317707</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>0.321056</td>\n",
       "      <td>0.288848</td>\n",
       "      <td>0.249610</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>1.356100</td>\n",
       "      <td>1.312795</td>\n",
       "      <td>0.515500</td>\n",
       "      <td>0.396928</td>\n",
       "      <td>0.283021</td>\n",
       "      <td>0.239456</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>1.352200</td>\n",
       "      <td>1.316145</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.489674</td>\n",
       "      <td>0.277538</td>\n",
       "      <td>0.230717</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.380200</td>\n",
       "      <td>1.317088</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.323415</td>\n",
       "      <td>0.285808</td>\n",
       "      <td>0.243861</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>1.359000</td>\n",
       "      <td>1.316537</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.322058</td>\n",
       "      <td>0.283687</td>\n",
       "      <td>0.240305</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.369800</td>\n",
       "      <td>1.316861</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.321627</td>\n",
       "      <td>0.285666</td>\n",
       "      <td>0.243160</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 1.381722092628479, 'eval_accuracy': 0.486, 'eval_precision': 0.27523213925002504, 'eval_recall': 0.25627310887950566, 'eval_f1-score': 0.20800118134501563, 'eval_support': 2000.0, 'eval_runtime': 22.5217, 'eval_samples_per_second': 88.803, 'eval_steps_per_second': 5.55, 'epoch': 10.0}\n",
      "+-------------------------+------------+\n",
      "| Метрика                 |   Значение |\n",
      "+=========================+============+\n",
      "| eval_loss               |     1.3817 |\n",
      "+-------------------------+------------+\n",
      "| eval_accuracy           |     0.4860 |\n",
      "+-------------------------+------------+\n",
      "| eval_precision          |     0.2752 |\n",
      "+-------------------------+------------+\n",
      "| eval_recall             |     0.2563 |\n",
      "+-------------------------+------------+\n",
      "| eval_f1-score           |     0.2080 |\n",
      "+-------------------------+------------+\n",
      "| eval_support            |  2000.0000 |\n",
      "+-------------------------+------------+\n",
      "| eval_runtime            |    22.5217 |\n",
      "+-------------------------+------------+\n",
      "| eval_samples_per_second |    88.8030 |\n",
      "+-------------------------+------------+\n",
      "| eval_steps_per_second   |     5.5500 |\n",
      "+-------------------------+------------+\n",
      "| epoch                   |    10.0000 |\n",
      "+-------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Кастомная классификационная голова\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, 1024)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.out_proj = nn.Linear(1024, num_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, pooled_output):\n",
    "        x = self.dense(pooled_output)  # [batch_size, 256]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.out_proj(x)        # [batch_size, num_labels]\n",
    "\n",
    "# Модифицируем модель BERT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels)\n",
    ")\n",
    "\n",
    "# Замораживаем все слои BERT\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Добавляем кастомную голову\n",
    "hidden_size = model.config.hidden_size  # 768 для bert-base\n",
    "num_labels = len(labels)                          # 6 эмоций в датасете\n",
    "model.classifier = CustomClassifier(hidden_size, num_labels)\n",
    "\n",
    "# Проверяем, что обучаются только параметры классификатора\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Обучается: {name}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    learning_rate=1e-4, # Больше lr, так как обучаем только голову\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    max_steps=10000,\n",
    "    logging_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"f1-score\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    # lr_scheduler_type=\"cosine\",\n",
    "    # warmup_steps=500\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 15,360 || all params: 109,502,214 || trainable%: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/5000 [03:12<12:38:49,  9.14s/it]\n",
      "  4%|▍         | 100/2500 [01:33<32:01,  1.25it/s]\n",
      "  4%|▍         | 100/2500 [01:33<32:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8187, 'grad_norm': 0.17120012640953064, 'learning_rate': 0.00028799999999999995, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 200/2500 [02:54<30:46,  1.25it/s]\n",
      "  8%|▊         | 200/2500 [02:54<30:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7639, 'grad_norm': 0.30830827355384827, 'learning_rate': 0.000276, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 300/2500 [04:14<29:27,  1.24it/s]\n",
      " 12%|█▏        | 300/2500 [04:14<29:27,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.678, 'grad_norm': 0.3930996060371399, 'learning_rate': 0.00026399999999999997, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 400/2500 [05:35<28:04,  1.25it/s]\n",
      " 16%|█▌        | 400/2500 [05:35<28:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6494, 'grad_norm': 0.4718685448169708, 'learning_rate': 0.00025199999999999995, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 500/2500 [06:55<26:47,  1.24it/s]\n",
      " 20%|██        | 500/2500 [06:55<26:47,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6321, 'grad_norm': 0.4933715760707855, 'learning_rate': 0.00023999999999999998, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 600/2500 [08:16<25:31,  1.24it/s]\n",
      " 24%|██▍       | 600/2500 [08:16<25:31,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6107, 'grad_norm': 0.6840925812721252, 'learning_rate': 0.00022799999999999999, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 700/2500 [09:36<24:03,  1.25it/s]\n",
      " 28%|██▊       | 700/2500 [09:36<24:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6053, 'grad_norm': 0.6605125069618225, 'learning_rate': 0.00021599999999999996, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 800/2500 [10:56<22:44,  1.25it/s]\n",
      " 32%|███▏      | 800/2500 [10:56<22:44,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5969, 'grad_norm': 0.8295512795448303, 'learning_rate': 0.000204, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 900/2500 [12:17<21:23,  1.25it/s]\n",
      " 36%|███▌      | 900/2500 [12:17<21:23,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6125, 'grad_norm': 0.7219657897949219, 'learning_rate': 0.00019199999999999998, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1000/2500 [13:37<20:05,  1.24it/s]\n",
      " 40%|████      | 1000/2500 [13:37<20:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6037, 'grad_norm': 0.544520914554596, 'learning_rate': 0.00017999999999999998, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1100/2500 [14:58<18:45,  1.24it/s]\n",
      " 44%|████▍     | 1100/2500 [14:58<18:45,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5978, 'grad_norm': 0.6628518104553223, 'learning_rate': 0.000168, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1200/2500 [16:27<20:04,  1.08it/s]\n",
      " 48%|████▊     | 1200/2500 [16:27<20:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.586, 'grad_norm': 0.6603737473487854, 'learning_rate': 0.000156, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1300/2500 [18:00<18:31,  1.08it/s]\n",
      " 52%|█████▏    | 1300/2500 [18:00<18:31,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5808, 'grad_norm': 0.7615088820457458, 'learning_rate': 0.00014399999999999998, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1400/2500 [19:33<16:59,  1.08it/s]\n",
      " 56%|█████▌    | 1400/2500 [19:33<16:59,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.593, 'grad_norm': 0.7308874130249023, 'learning_rate': 0.00013199999999999998, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1500/2500 [21:05<15:26,  1.08it/s]\n",
      " 60%|██████    | 1500/2500 [21:05<15:26,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5965, 'grad_norm': 0.7331592440605164, 'learning_rate': 0.00011999999999999999, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1600/2500 [22:38<13:53,  1.08it/s]\n",
      " 64%|██████▍   | 1600/2500 [22:38<13:53,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5865, 'grad_norm': 0.7494508028030396, 'learning_rate': 0.00010799999999999998, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1700/2500 [24:11<12:21,  1.08it/s]\n",
      " 68%|██████▊   | 1700/2500 [24:11<12:21,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5854, 'grad_norm': 0.9168499708175659, 'learning_rate': 9.599999999999999e-05, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1800/2500 [25:44<10:52,  1.07it/s]\n",
      " 72%|███████▏  | 1800/2500 [25:44<10:52,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5882, 'grad_norm': 0.802970826625824, 'learning_rate': 8.4e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1900/2500 [27:13<08:14,  1.21it/s]\n",
      " 76%|███████▌  | 1900/2500 [27:13<08:14,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5878, 'grad_norm': 1.4894355535507202, 'learning_rate': 7.199999999999999e-05, 'epoch': 3.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2000/2500 [28:33<06:30,  1.28it/s]\n",
      " 80%|████████  | 2000/2500 [28:33<06:30,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5678, 'grad_norm': 0.881062924861908, 'learning_rate': 5.9999999999999995e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 2100/2500 [29:51<05:13,  1.28it/s]\n",
      " 84%|████████▍ | 2100/2500 [29:51<05:13,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5794, 'grad_norm': 0.5813419222831726, 'learning_rate': 4.7999999999999994e-05, 'epoch': 4.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2200/2500 [31:09<03:54,  1.28it/s]\n",
      " 88%|████████▊ | 2200/2500 [31:09<03:54,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5765, 'grad_norm': 1.4918239116668701, 'learning_rate': 3.5999999999999994e-05, 'epoch': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 2300/2500 [32:28<02:36,  1.28it/s]\n",
      " 92%|█████████▏| 2300/2500 [32:28<02:36,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5803, 'grad_norm': 0.815494179725647, 'learning_rate': 2.3999999999999997e-05, 'epoch': 4.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 2400/2500 [33:46<01:18,  1.28it/s]\n",
      " 96%|█████████▌| 2400/2500 [33:46<01:18,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5756, 'grad_norm': 1.0910353660583496, 'learning_rate': 1.1999999999999999e-05, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [35:04<00:00,  1.28it/s]\n",
      "100%|██████████| 2500/2500 [35:04<00:00,  1.28it/s]\n",
      "100%|██████████| 2500/2500 [35:04<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5852, 'grad_norm': 0.8338690996170044, 'learning_rate': 0.0, 'epoch': 5.0}\n",
      "{'train_runtime': 2104.5312, 'train_samples_per_second': 38.013, 'train_steps_per_second': 1.188, 'train_loss': 1.6135260314941406, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:25<00:00,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "| Метрика                 |   Значение |\n",
      "+=========================+============+\n",
      "| eval_loss               |     1.5444 |\n",
      "+-------------------------+------------+\n",
      "| eval_accuracy           |     0.4125 |\n",
      "+-------------------------+------------+\n",
      "| eval_precision          |     0.1381 |\n",
      "+-------------------------+------------+\n",
      "| eval_recall             |     0.2071 |\n",
      "+-------------------------+------------+\n",
      "| eval_f1-score           |     0.1564 |\n",
      "+-------------------------+------------+\n",
      "| eval_support            |  2000.0000 |\n",
      "+-------------------------+------------+\n",
      "| eval_runtime            |    25.8858 |\n",
      "+-------------------------+------------+\n",
      "| eval_samples_per_second |    77.2620 |\n",
      "+-------------------------+------------+\n",
      "| eval_steps_per_second   |     9.6580 |\n",
      "+-------------------------+------------+\n",
      "| epoch                   |     5.0000 |\n",
      "+-------------------------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import (\n",
    "    PromptTuningConfig,\n",
    "    get_peft_model,\n",
    "    TaskType\n",
    ")\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# 1. Конфигурация Prompt Tuning\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    num_virtual_tokens=20,  # Длина мягкого промпта\n",
    "    token_dim=768,          # Размерность эмбеддингов BERT\n",
    "    # num_transformer_submodules=1,  # Для encoder-only моделей\n",
    "    prompt_tuning_init=\"TEXT\",\n",
    "    prompt_tuning_init_text=\"Classify the emotion in the text:\",\n",
    "    base_model_name_or_path=\"bert-base-uncased\",\n",
    "    tokenizer_name_or_path=\"bert-base-uncased\"\n",
    ")\n",
    "\n",
    "# 2. Загрузка модели\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-uncased\",\n",
    "    num_labels=len(labels),\n",
    "    return_dict=True\n",
    ")\n",
    "\n",
    "# 3. Обертка модели в PEFT\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()  # Обучаемые параметры: ~0.1%\n",
    "\n",
    "# 4. Заморозка основной модели (опционально)\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./peft_results\",\n",
    "    learning_rate=3e-4,           # Выше обычного для промптов\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=5,          # Нужно больше эпох\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 299,526 || all params: 109,786,380 || trainable%: 0.2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 105/5000 [01:33<1:13:00,  1.12it/s]\n",
      "  8%|▊         | 200/2500 [02:48<31:26,  1.22it/s]\n",
      "  8%|▊         | 200/2500 [02:48<31:26,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.349, 'grad_norm': 2.0876481533050537, 'learning_rate': 0.000276, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 400/2500 [05:33<28:45,  1.22it/s]\n",
      " 16%|█▌        | 400/2500 [05:33<28:45,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8296, 'grad_norm': 3.4698805809020996, 'learning_rate': 0.00025199999999999995, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 500/2500 [06:55<27:22,  1.22it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "                                                  \n",
      " 20%|██        | 500/2500 [07:25<27:22,  1.22it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47649213671684265, 'eval_accuracy': 0.8365, 'eval_precision': 0.8267511170691882, 'eval_recall': 0.7541225013167661, 'eval_f1-score': 0.7820812942751005, 'eval_support': 2000.0, 'eval_runtime': 28.4486, 'eval_samples_per_second': 70.302, 'eval_steps_per_second': 8.788, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 600/2500 [08:46<25:54,  1.22it/s]  \n",
      " 24%|██▍       | 600/2500 [08:46<25:54,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5413, 'grad_norm': 4.005258083343506, 'learning_rate': 0.00022799999999999999, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 800/2500 [11:31<23:23,  1.21it/s]\n",
      " 32%|███▏      | 800/2500 [11:31<23:23,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3978, 'grad_norm': 3.885700225830078, 'learning_rate': 0.000204, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1000/2500 [14:15<20:26,  1.22it/s]\n",
      " 40%|████      | 1000/2500 [14:15<20:26,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3599, 'grad_norm': 4.011159896850586, 'learning_rate': 0.00017999999999999998, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                   \n",
      "\n",
      " 40%|████      | 1000/2500 [14:45<20:26,  1.22it/s]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2431042194366455, 'eval_accuracy': 0.9215, 'eval_precision': 0.8936483063804851, 'eval_recall': 0.9011226544768344, 'eval_f1-score': 0.8970911641926804, 'eval_support': 2000.0, 'eval_runtime': 28.3684, 'eval_samples_per_second': 70.501, 'eval_steps_per_second': 8.813, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1200/2500 [17:27<16:56,  1.28it/s]  \n",
      " 48%|████▊     | 1200/2500 [17:27<16:56,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2753, 'grad_norm': 2.9487192630767822, 'learning_rate': 0.000156, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1400/2500 [20:04<14:21,  1.28it/s]\n",
      " 56%|█████▌    | 1400/2500 [20:04<14:21,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2438, 'grad_norm': 3.2253737449645996, 'learning_rate': 0.00013199999999999998, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1500/2500 [21:22<13:02,  1.28it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                   \n",
      "\n",
      " 60%|██████    | 1500/2500 [21:50<13:02,  1.28it/s]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19373109936714172, 'eval_accuracy': 0.9285, 'eval_precision': 0.8998014687986707, 'eval_recall': 0.9034757221810993, 'eval_f1-score': 0.9011861731340605, 'eval_support': 2000.0, 'eval_runtime': 27.0616, 'eval_samples_per_second': 73.906, 'eval_steps_per_second': 9.238, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1600/2500 [23:09<11:45,  1.28it/s]  \n",
      " 64%|██████▍   | 1600/2500 [23:09<11:45,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2356, 'grad_norm': 2.7473952770233154, 'learning_rate': 0.00010799999999999998, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1800/2500 [25:45<09:08,  1.28it/s]\n",
      " 72%|███████▏  | 1800/2500 [25:45<09:08,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2073, 'grad_norm': 1.419308066368103, 'learning_rate': 8.4e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2000/2500 [28:22<06:31,  1.28it/s]\n",
      " 80%|████████  | 2000/2500 [28:22<06:31,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1996, 'grad_norm': 5.523075580596924, 'learning_rate': 5.9999999999999995e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                   \n",
      "\n",
      " 80%|████████  | 2000/2500 [28:49<06:31,  1.28it/s]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1785881668329239, 'eval_accuracy': 0.936, 'eval_precision': 0.9144537697201054, 'eval_recall': 0.9291076530980072, 'eval_f1-score': 0.920991715768876, 'eval_support': 2000.0, 'eval_runtime': 25.8254, 'eval_samples_per_second': 77.443, 'eval_steps_per_second': 9.68, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2200/2500 [31:25<03:54,  1.28it/s]  \n",
      " 88%|████████▊ | 2200/2500 [31:25<03:54,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.18, 'grad_norm': 4.138106822967529, 'learning_rate': 3.5999999999999994e-05, 'epoch': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 2400/2500 [34:02<01:18,  1.28it/s]\n",
      " 96%|█████████▌| 2400/2500 [34:02<01:18,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1844, 'grad_norm': 2.3966174125671387, 'learning_rate': 1.1999999999999999e-05, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [35:20<00:00,  1.28it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                   \n",
      "\n",
      "100%|██████████| 2500/2500 [35:48<00:00,  1.28it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 2500/2500 [35:48<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1654692143201828, 'eval_accuracy': 0.938, 'eval_precision': 0.9193392246932405, 'eval_recall': 0.9178323360827396, 'eval_f1-score': 0.9184753633939998, 'eval_support': 2000.0, 'eval_runtime': 27.0808, 'eval_samples_per_second': 73.853, 'eval_steps_per_second': 9.232, 'epoch': 5.0}\n",
      "{'train_runtime': 2148.5027, 'train_samples_per_second': 37.235, 'train_steps_per_second': 1.164, 'train_loss': 0.40780635681152344, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:26<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "| Метрика                 |   Значение |\n",
      "+=========================+============+\n",
      "| eval_loss               |     0.1978 |\n",
      "+-------------------------+------------+\n",
      "| eval_accuracy           |     0.9220 |\n",
      "+-------------------------+------------+\n",
      "| eval_precision          |     0.8764 |\n",
      "+-------------------------+------------+\n",
      "| eval_recall             |     0.8873 |\n",
      "+-------------------------+------------+\n",
      "| eval_f1-score           |     0.8813 |\n",
      "+-------------------------+------------+\n",
      "| eval_support            |  2000.0000 |\n",
      "+-------------------------+------------+\n",
      "| eval_runtime            |    26.8544 |\n",
      "+-------------------------+------------+\n",
      "| eval_samples_per_second |    74.4760 |\n",
      "+-------------------------+------------+\n",
      "| eval_steps_per_second   |     9.3090 |\n",
      "+-------------------------+------------+\n",
      "| epoch                   |     5.0000 |\n",
      "+-------------------------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from peft import (\n",
    "    LoraConfig, \n",
    "    TaskType, \n",
    "    get_peft_model\n",
    ")\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# 1. Конфигурация LoRA\n",
    "lora_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        inference_mode=False,\n",
    "        r=8,                # Ранг адаптеров\n",
    "        lora_alpha=16,      # Коэффициент масштабирования\n",
    "        lora_dropout=0.1,   # Дропаут для регуляризации\n",
    "        target_modules=[\"query\", \"value\"],  # Слои для применения LoRA\n",
    "        bias=\"none\"\n",
    "    )\n",
    "\n",
    "# 2. Загрузка модели\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-uncased\",\n",
    "    num_labels=6\n",
    ")\n",
    "\n",
    "\n",
    "# Создаем новую конфиг\n",
    "peft_config = lora_config\n",
    "\n",
    "# Обертка модели\n",
    "lora_model = get_peft_model(model, peft_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "# Обучение\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./lora_results\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=200\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
